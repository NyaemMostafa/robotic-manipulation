{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows a simple example of inverse kinematics (as seen in class) for the Kuka iiwa robot using a QP instead of the pseudo-inverse.\n",
    "\n",
    "The notebook contains:\n",
    "* an example for end-effector position goals only\n",
    "* an example for end-effector position goals with optimization of a posture in the nullspace\n",
    "* an example for end-effector pose (positions + orientation) with nullspace posture optimization\n",
    "\n",
    "## Requirement\n",
    "To run these examples you will need to install these two packages:\n",
    "* [Pinocchio](https://github.com/stack-of-tasks/pinocchio), a rigid body dynamics library (which does all the kinematics computation for us). You can install it directly through conda `conda install pinocchio -c conda-forge` or follow the [installation instructions](https://stack-of-tasks.github.io/pinocchio/download.html#Install_3)\n",
    "* [Meshcat](https://github.com/rdeits/meshcat-python) which is used for the visualization of the robot. You can install it directly through pip `pip install meshcat`\n",
    "* [ProxSuite](https://simple-robotics.github.io/proxsuite/) which is used for the QP solver. You can install it directly through conda `conda install proxsuite -c conda-forge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pinocchio as pin\n",
    "import meshcat\n",
    "import proxsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7002/static/\n"
     ]
    }
   ],
   "source": [
    "# the directory where the robot models are located\n",
    "package_dirs = './urdf/'\n",
    "\n",
    "# the name of the URDF model (the robot model)\n",
    "urdf_file = 'iiwa.urdf'\n",
    "END_EFF_FRAME_ID = 17 # number of the frame corresponding to the end-effector\n",
    "\n",
    "# we load the urdf models with Pinocchio\n",
    "urdf = package_dirs + urdf_file\n",
    "robot = pin.RobotWrapper.BuildFromURDF(urdf, package_dirs)\n",
    "\n",
    "# we create the visualization\n",
    "viz = pin.visualize.MeshcatVisualizer(robot.model, robot.collision_model, robot.visual_model)\n",
    "\n",
    "try:\n",
    "    viz.initViewer(open=True)\n",
    "except ImportError as err:\n",
    "    print(\"Error while initializing the viewer. It seems you should install Python meshcat\")\n",
    "    print(err)\n",
    "    sys.exit(0)\n",
    "    \n",
    "viz.loadViewerModel()\n",
    "\n",
    "# place the robot in its default position and display it\n",
    "q0 = pin.neutral(robot.model)\n",
    "viz.display(q0)\n",
    "\n",
    "# create a ball to visualize the goal\n",
    "viz.viewer['ball'].set_object(meshcat.geometry.Sphere(0.05), \n",
    "                              meshcat.geometry.MeshLambertMaterial(\n",
    "                             color=0xff22dd,\n",
    "                             reflectivity=0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inverse kinematics with end-effector goal position\n",
    "\n",
    "Here we want to find the inverse kinematics of the robot to reach a desired end-effector position $p_{des}$ by using a QP solver. \n",
    "\n",
    "We setup 3 different possible QP (you can set the variable ``QP_type`` to 1, 2 or 3 to select which one to run).\n",
    "\n",
    "### First QP option: simple task optimization\n",
    "The first QP is simple, we simply optimize the following\n",
    "$$\\min_{\\Delta\\theta} \\frac{1}{2}\\|J \\Delta\\theta + p(\\theta)_{current} - p_{des}\\|^2$$\n",
    "which is equivalent (dropping the constant terms) to optimizing\n",
    "$$\\min_{\\Delta\\theta} \\frac{1}{2}\\Delta\\theta^T J^T J \\Delta\\theta + (p(\\theta)_{current} - p_{des})^TJ\\Delta\\theta$$\n",
    "\n",
    "we further add constraints to ensure we take a small step at each iteration $|\\Delta \\theta_i| < 0.1$\n",
    "\n",
    "### Second QP option: adding a linear constraint on the second joint\n",
    "The second QP adds a constraint to prevent the first joint from moving\n",
    "   $$\\min_{\\Delta\\theta} \\frac{1}{2}\\|J \\Delta\\theta + p(\\theta)_{current} - p_{des}\\|^2$$\n",
    "   $$\\textrm{subject to} \\ \\ \\begin{bmatrix}1 & 0 & 0 & 0 & 0 & 0 & 0 \\end{bmatrix} \\Delta\\theta = 0 \\ \\ \\textrm{and} \\ \\ |\\Delta \\theta_i| < 0.1$$\n",
    "\n",
    "We will see that in this case, the robot cannot reach its goal but will find the closest solution it can.\n",
    "\n",
    "### Third QP option: adding a cost to optimize joint configurations as well\n",
    "The third QP tries to both reach the desired end-effector position (high weight) and optimize the joint positions to reach a desired position\n",
    "   $$\\min_{\\Delta\\theta} \\frac{1}{2}\\left(1000*\\|J \\Delta\\theta + p(\\theta)_{current} - p_{des}\\|^2 + \\|\\theta + \\Delta\\theta - \\theta_{desired}\\|^2 \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no good solution found\n",
      "current guess is:\n",
      " [-5.58670200e-06  1.88917053e+00  1.57748291e+00 -1.39693957e+00\n",
      " -1.57903939e+00 -6.51670225e-03  0.00000000e+00]\n",
      "this gives an end-effector position of [0.48580499 0.51312502 0.20432934]\n",
      "the desired end-effector position was [0.5 0.6 0.2]\n"
     ]
    }
   ],
   "source": [
    "QP_type = 1\n",
    "\n",
    "# we set the desired end-effector position (feel free to change this)\n",
    "p_des = np.array([0.5,.6, 0.2])\n",
    "viz.viewer['ball'].set_transform(meshcat.transformations.translation_matrix(p_des))\n",
    "\n",
    "# we start with a random guess for the joint positions (q) \n",
    "# here we use the default robot position (for simplicity)\n",
    "q = pin.neutral(robot.model)\n",
    "viz.display(q)\n",
    "\n",
    "## we iterate up to 500 times\n",
    "max_iterations = 500\n",
    "for i in range(max_iterations):\n",
    "    # compute the forward kinematics\n",
    "    robot.forwardKinematics(q)\n",
    "    \n",
    "    # get the position of the end-effector\n",
    "    T_S_F = robot.framePlacement(q, END_EFF_FRAME_ID)\n",
    "    p_current = T_S_F.translation\n",
    "    \n",
    "    # get the Jacobian with the right frame \n",
    "    # (we use a frame oriented like the spatial frame but located at the end-effector)\n",
    "    J = robot.computeFrameJacobian(q, END_EFF_FRAME_ID)\n",
    "    J = T_S_F.rotation @ J[:3,:]\n",
    "    \n",
    "    # compute the endeffector error\n",
    "    err =  p_current - p_des\n",
    "    \n",
    "    # here we check if we are done or if we need to continue\n",
    "    err_norm = np.linalg.norm(err)\n",
    "    if err_norm < 0.005: # we stop if we have an error < 5mm\n",
    "        print(f'done in {i} steps')\n",
    "        print(f'we found joint positions:\\n {q}')\n",
    "        print(f'this gives an end-effector position of {T_S_F.translation}')\n",
    "        print(f'the desired end-effector position was {p_des}')\n",
    "        break\n",
    "    if i==max_iterations-1:\n",
    "        print('no good solution found')\n",
    "        print(f'current guess is:\\n {q}')\n",
    "        print(f'this gives an end-effector position of {T_S_F.translation}')\n",
    "        print(f'the desired end-effector position was {p_des}')\n",
    "\n",
    "    ## we setup the QP\n",
    "    if QP_type == 1:\n",
    "        H = J.T @ J\n",
    "        h = J.T @ err\n",
    "        qp = proxsuite.proxqp.dense.QP(robot.nv, 0, 0, True)\n",
    "        l_box = -np.ones(robot.nv) * 0.1 #lower limit\n",
    "        u_box = np.ones(robot.nv) * 0.1 #upper limit\n",
    "        qp.init(H, h, None, None, None, None, None, l_box, u_box)\n",
    "    elif QP_type == 2:\n",
    "        H = J.T @ J\n",
    "        h = J.T @ err\n",
    "        qp = proxsuite.proxqp.dense.QP(robot.nv, 1, 0, True)\n",
    "        A = np.array([[1,0,0,0,0,0,0]])\n",
    "        b = np.array([0])\n",
    "        l_box = -np.ones(robot.nv) * 0.1 #lower limit\n",
    "        u_box = np.ones(robot.nv) * 0.1 #upper limit\n",
    "        qp.init(H, h, A, b, None, None, None, l_box, u_box)\n",
    "    elif QP_type == 3:\n",
    "        theta_desired = np.array([3., 3., -3, 0., -2., 1., 1.])\n",
    "        # theta_desired = np.zeros([robot.nv])\n",
    "        H = 1000 * J.T @ J + np.identity(robot.nv)\n",
    "        h = 1000 * J.T @ err + (q - theta_desired)\n",
    "        qp = proxsuite.proxqp.dense.QP(robot.nv, 0, 0)\n",
    "        qp.init(H, h)\n",
    "    else:\n",
    "        print('ERROR this mode does not exist')\n",
    "        raise\n",
    "        \n",
    "    qp.solve()\n",
    "    dq = qp.results.x\n",
    "    \n",
    "    # compute do one step of diffential inverse kinematics\n",
    "    epsilon = 10e-2\n",
    "    # we update our guess for the joint positions\n",
    "    q = q + epsilon * dq\n",
    "    \n",
    "    # we display the new guess (and sleep to make it nicely visible with rendering)\n",
    "    # turn this off to see how fast this really is\n",
    "    viz.display(q)\n",
    "    time.sleep(0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inverse kinematics with full pose goal (position + orientation)\n",
    "We can also optimize the full pose of the end-effector using the log by optimizing\n",
    "\n",
    "$$\\min_{\\Delta\\theta} \\frac{1}{2}\\|J \\Delta\\theta - \\log(T_{current}^{-1} T_{des})\\|^2$$\n",
    "\n",
    "with constraint at each iteration $|\\Delta \\theta_i| < 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 315 steps\n",
      "we found joint positions:\n",
      " [ 1.52943595  2.10437844  0.78963727  1.52460117 -0.85008383 -0.95053851\n",
      " -0.46981443]\n",
      "this gives an end-effector position of \n",
      "  R =\n",
      "           1 -9.97785e-05 -0.000613217\n",
      " 9.91087e-05     0.999999  -0.00109231\n",
      " 0.000613325   0.00109225     0.999999\n",
      "  p = 0.304946 0.508306 0.500216\n",
      "\n",
      "the desired end-effector position was \n",
      "  R =\n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "  p = 0.3 0.5 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inverse kinematics with nullspace\n",
    "\n",
    "# we set the desired end-effector position and orientation (feel free to change this)\n",
    "rot_des = np.array([[1,0,0],[0,1,0],[0,0,1]]) # desired orientation matrix\n",
    "pos_des = np.array([0.3,.5, 0.5]) # desired position\n",
    "end_eff_desired = pin.SE3(rot_des,pos_des) # we create a homogeneous transform\n",
    "\n",
    "# we display the goal\n",
    "viz.viewer['ball'].set_transform(meshcat.transformations.translation_matrix(end_eff_desired.translation)) \n",
    "\n",
    "# we start with a random guess for the joint positions (q) \n",
    "# here we use the default robot position\n",
    "q = pin.neutral(robot.model)\n",
    "viz.display(q)\n",
    "\n",
    "## we iterate up to 500 times\n",
    "max_iterations = 500\n",
    "for i in range(max_iterations):\n",
    "    # compute the forward kinematics\n",
    "    robot.forwardKinematics(q)\n",
    "    \n",
    "    # get the position of the end-effector\n",
    "    T_S_F = robot.framePlacement(q, END_EFF_FRAME_ID)\n",
    "    \n",
    "    # get the Jacobian with the right frame \n",
    "    # CAREFUL we use a body Jacobian for this task!\n",
    "    J = robot.computeFrameJacobian(q, END_EFF_FRAME_ID)\n",
    "    \n",
    "    # compute the endeffector error\n",
    "    # to get the error we use the log (implemented in Pinocchio)\n",
    "    err = -pin.log(T_S_F.actInv(end_eff_desired)).vector\n",
    "    \n",
    "    # here we check if we are done or if we need to continue\n",
    "    err_norm = np.linalg.norm(err)\n",
    "    if err_norm < 0.01:\n",
    "        print(f'done in {i} steps')\n",
    "        print(f'we found joint positions:\\n {q}')\n",
    "        print(f'this gives an end-effector position of \\n{T_S_F}')\n",
    "        print(f'the desired end-effector position was \\n{end_eff_desired}')\n",
    "        break\n",
    "    if i==max_iterations-1:\n",
    "        print('no good solution found')\n",
    "        print(f'current guess is:\\n {q}')\n",
    "        print(f'this gives an end-effector position of \\n{T_S_F}')\n",
    "        print(f'the desired end-effector position was \\n{end_eff_desired}')\n",
    "\n",
    "    ## solve the QP\n",
    "    H = J.T @ J\n",
    "    h = J.T @ err\n",
    "    qp = proxsuite.proxqp.dense.QP(robot.nv, 0, 0, True)\n",
    "    l_box = -np.ones(robot.nv) * 0.1 #lower limit\n",
    "    u_box = np.ones(robot.nv) * 0.1 #upper limit\n",
    "    qp.init(H, h, None, None, None, None, None, l_box, u_box)\n",
    "    qp.solve()\n",
    "    dq = qp.results.x\n",
    "    \n",
    "    # compute do one step of diffentiual inverse kinematics\n",
    "    epsilon = 10e-2\n",
    "    # we update our guess for the joint positions\n",
    "    q = q + epsilon * dq\n",
    "    \n",
    "    # we display the new guess (and sleep to make it nicely visible with rendering)\n",
    "    # turn this off to see how fast this really is\n",
    "    viz.display(q)\n",
    "    time.sleep(0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
